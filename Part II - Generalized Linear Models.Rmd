---
title: "Part II: Generalized Linear Models"
output:
  html_document: default
  pdf_document: default
---

# Load Packages 

Again, we must load the packages that will be used in the first part of this workshop.


```{r, message=FALSE, warning=FALSE }
library(pastecs, quietly = TRUE)
library(lm.beta,  quietly = TRUE)
library(lmtest,  quietly = TRUE)
library(foreign,  quietly = TRUE)
library(lattice,  quietly = TRUE)
library(lme4,  quietly = TRUE)
library(nlme,  quietly = TRUE)
library(survival,  quietly = TRUE)
library(dplyr,  quietly = TRUE)
library(ggfortify,  quietly = TRUE)
library(survminer,  quietly = TRUE)
library(rms,  quietly = TRUE)
library(MASS, quietly = TRUE)
```

# Generalized linear models

## Logistic regression
```{r}
data <- iris
data$Sepal.Width_binary <- ifelse(data$Sepal.Width >= median(data$Sepal.Width), 1, 0)
logit <- glm(Sepal.Width_binary ~ Sepal.Length + as.factor(Species), data = data, family = "binomial")
summary(logit)
```
 Plot the logistic regression line and smoothing line

```{r}
plot(Sepal.Width_binary~Sepal.Length, data=data)
lines(data$Sepal.Length[order(data$Sepal.Length)], logit$fitted[order(data$Sepal.Length)], 
       type="l", col="red")
title(main="Data with Fitted Logistic Regression Line")

data.smooth <- predict(loess(Sepal.Width_binary~Sepal.Length, data=data, span=0.75))
points(data$Sepal.Length[order(data$Sepal.Length)], data.smooth[order(data$Sepal.Length)], 
      type="b",lty=2, col="green")
legend(5,0.9, c("logistic","loess smooth"), col=c("red", "green"), lty=c(1:2))
```

 Exponentiated coefficients
```{r}
exp(coef(logit))
```


# Poisson and Quasi-Poisson Regression

```{r}
attach(epil)
summary(epil)
```

```{r}
df=epil[epil$V4 == 1,]
df <- subset(df, select = -c(V4,period))

sapply(df, class)
ggplot(df,aes(x=df$y))+ 
  geom_histogram(binwidth = 1, center = 0.5) +
  scale_x_continuous(breaks=seq(1,max(df$y), by = 5))+
  ylab("Count")+ xlab("data")+
  ggtitle("Histogram plot of the number of epileptic seizures after the last 2 weeks")
```

```{r}
model = glm(y~ 1, family=poisson(link=log),data=df)
summary(model)
```


```{r}
print(coef(model))
```

```{r}
print(data.frame(df$y,model$fitted))
```

```{r}
model$linear.predictors
exp(model$linear.predictors)
```

### Hypothesis test for goodness of fit
```{r}
print(1-pchisq(model$deviance,model$df.residual))
```

plot data comparison
```{r}
df_original = data.frame(data=df$y)
df_fitted = data.frame(data=model$fitted)
plot(df_original$data,df_fitted$data,ylab='fit data',xlab='original data')
```


add a Covariate to the fit -- treatment
```{r}
model = glm(y~ 1 +trt, family=poisson(link=log),df)
summary(model)
print(1-pchisq(model$deviance,model$df.residual))
```

```{r}
df_fitted = data.frame(data=model$fitted)
df_fitted$name = "fitted"
plot(df_original$data,df_fitted$data)
```

### add a Covariate to the fit -- treatment, age

```{r}
model = glm(y ~ 1 +trt*age, family=poisson(link=log),df)
summary(model)
```

```{r}
print(1-pchisq(model$deviance,model$df.residual))
df_fitted = data.frame(data=model$fitted)
combined=rbind(df_original,df_fitted)
plot(df_original$data,df_fitted$data)
```

## Overdispersion might be present -- try Quasipossion  
```{r}
model = glm(y ~ 1 +trt*age, family=quasipoisson(link=log),df)
summary(model)

print(1-pchisq(model$deviance,model$df.residual))

df_fitted = data.frame(data=model$fitted)

combined=rbind(df_original,df_fitted)

plot(df_original$data,df_fitted$data)
detach(epil)
```